seed_everything: 42
trainer:
  enable_checkpointing: true
  accelerator: auto
  devices: auto
  max_epochs: 100
#  gradient_clip_val: 1.0
  sync_batchnorm: false
  precision: 32
  enable_model_summary: true
  weights_save_path: null
  num_sanity_val_steps: 2
  benchmark: true
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: ot-vae-lightning
      entity: gip
      dir: dad
      log_model: true
      name: defaults
model:
  expansion: 1
  learning_rate: 1e-3
  lr_sched_metric: psnr
  conditional: false
  checkpoints: null
  metrics:
    class_path: torchmetrics.MetricCollection
    init_args:
      metrics:
        psnr: torchmetrics.image.psnr.PeakSignalNoiseRatio
  encoder:
    class_path: ot_vae_lightning.networks.ViT
    init_args:
      image_size: 32
      patch_size: 8
      dim: 128
      depth: 3
      heads: 4
      mlp_dim: 512
      channels: 3
      dim_head: 32
      dropout: 0.1
      emb_dropout: 0.
      n_embed_tokens: 0
      n_input_tokens: null
      output_tokens: input
      patch_to_embed: true
      embed_to_patch: false
      num_classes: null
  decoder:
    class_path: ot_vae_lightning.networks.ViT
    init_args:
      image_size: 32
      patch_size: 8
      dim: 128
      depth: 3
      heads: 4
      mlp_dim: 512
      dim_head: 32
      channels: 3
      dropout: 0.1
      emb_dropout: 0
      n_embed_tokens: 0
      n_input_tokens: null
      output_tokens: input
      patch_to_embed: false
      embed_to_patch: true
      num_classes: null
  prior_kwargs:
    topk: null
    mode: smooth  # 'smooth', 'sample'
    loss: l2  # 'kl', 'l2'
    commitment_cost: 0.25
  prior:
    class_path: ot_vae_lightning.prior.codebook.CodebookPrior
    init_args:
      num_embeddings: 8192
      latent_size: [16, 128]
      embed_dims: [1]
      similarity_metric: l2
      separate_key_values: false
      loss_coeff: 0.1
      annealing_steps: 0
data:
  class_path: ot_vae_lightning.data.CIFAR10
  init_args:
    train_val_split: 0.9
    seed: 42
    train_batch_size: 100
    val_batch_size: 512
    test_batch_size: 512
    num_workers: 8
