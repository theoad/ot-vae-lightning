seed_everything: 42
trainer:
  max_epochs: 100
  num_sanity_val_steps: 50
  accelerator: gpu
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: ot-vae-lightning
      entity: gip
      dir: vae
      log_model: true
      name: ffhq-256x8x8
model:
  metrics:
    class_path: torchmetrics.MetricCollection
    init_args:
      metrics:
        psnr: torchmetrics.image.psnr.PeakSignalNoiseRatio
        fid: ot_vae_lightning.metrics.fid.FrechetInceptionDistance
  monitor: psnr
  mode: max
  autoencoder:
    class_path: ot_vae_lightning.networks.AutoEncoder
    init_args:
      in_features: 3
      in_resolution: 128
      latent_features: 128
      latent_resolution: 8
      double_encoded_features: false
      capacity: 32
      n_layers: 2
      down_up_sample: 2
      normalization: batch
      activation: relu
      equalized_lr: null
      dropout: 0.
      residual: add
      time_embed_dim: null
      max_attn_res: 0
      bias: true
data:
  class_path: ot_vae_lightning.data.FFHQ128
  init_args:
    test_val_split: 0.9
    seed: 42
    train_batch_size: 10
    val_batch_size: 20
    test_batch_size: 20
    num_workers: 10
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 1e-3
    betas: [0.9, 0.999]
#    weight_decay: 1e-4
lr_scheduler:
  class_path: pytorch_lightning.cli.ReduceLROnPlateau
  init_args:
    monitor: val/metrics/psnr
    mode: max
    factor: 0.75
    patience: 8
    verbose: True
    threshold: 1e-1
    min_lr: 1e-6