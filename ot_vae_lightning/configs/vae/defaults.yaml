seed_everything: 42
trainer:
  enable_checkpointing: true
  accelerator: auto
  devices: auto
  max_steps: 1000000
  gradient_clip_val: 1.0
  sync_batchnorm: false
  precision: 16
  enable_model_summary: true
  weights_save_path: null
  num_sanity_val_steps: 2
  benchmark: true
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: ot-vae-lightning
      entity: gip
      dir: vae
      log_model: true
      name: auto_diffusion
model:
  expansion: 1
  learning_rate: 5e-4
#  lr_sched_metric: fid
  conditional: false
  checkpoints: null
#  ema_decay: 0.999
  metrics:
    class_path: torchmetrics.MetricCollection
    init_args:
      metrics:
        psnr: torchmetrics.image.psnr.PeakSignalNoiseRatio
        fid: ot_vae_lightning.metrics.fid.FrechetInceptionDistance
  prior:
    class_path: ot_vae_lightning.prior.GaussianPrior
    init_args:
      loss_coeff: 0.1
      reparam_dim: 1
      empirical_kl: true
      annealing_steps: 0
      fixed_var: false
  autoencoder:
    class_path: ot_vae_lightning.networks.AutoEncoder
    init_args:
      in_features: 3
      in_resolution: 128
      latent_features: 512
      latent_resolution: 4
      double_encoded_features: true
      capacity: 16
      n_layers: 3
      down_up_sample: 2
      normalization: group
      activation: relu
      equalized_lr: true
      dropout: 0.
      residual: true
      time_embed_dim: 128
data:
  class_path: ot_vae_lightning.data.FFHQ128
  init_args:
    train_val_split: 0.9
    seed: 42
    train_batch_size: 32
    val_batch_size: 128
    test_batch_size: 128
    num_workers: 10
