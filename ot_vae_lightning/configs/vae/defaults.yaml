seed_everything: 42
trainer:
  max_steps: 100000
#  devices: auto
#  strategy: ddp_find_unused_parameters_false
#  gradient_clip_val: 1.0
#  precision: 16
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: ot-vae-lightning
      entity: gip
      dir: vae
      log_model: true
      name: ffhq-128x8x8
model:
  learning_rate: 1e-3
  metrics:
    class_path: torchmetrics.MetricCollection
    init_args:
      metrics:
        psnr: torchmetrics.image.psnr.PeakSignalNoiseRatio
        fid: ot_vae_lightning.metrics.fid.FrechetInceptionDistance
  autoencoder:
    class_path: ot_vae_lightning.networks.AutoEncoder
    init_args:
      in_features: 3
      in_resolution: 128
      latent_features: 128
      latent_resolution: 8
      double_encoded_features: false
      capacity: 32
      n_layers: 2
      down_up_sample: 2
      normalization: batch
      activation: leaky
      equalized_lr: 1
      dropout: 0.
      residual: add
      time_embed_dim: null
      max_attn_res: 0
      bias: true
data:
  class_path: ot_vae_lightning.data.FFHQ128
  init_args:
    test_val_split: 0.9
    seed: 42
    train_batch_size: 50
    val_batch_size: 100
    test_batch_size: 100
    num_workers: 10
